const e=JSON.parse('{"key":"v-b994661a","path":"/language/python/python-scrapy-debugging-spiders.html","title":"Scrapy入门（三）-调试(Debugging)Spiders","lang":"zh-CN","frontmatter":{"description":"1. 背景 而Scrapy的爬虫通常是在命令行中启动的，我们怎么去调试呢？ 2. 调试部署 1. 首先在setting.py同级目录下创建run.py文件。 image-20210311105958418 写入以下代码 其中name参数为spider的name。 接着在spider文件中设置断点。 image-20210311110405697 返回r...","head":[["meta",{"property":"og:url","content":"https://java.isture.com/language/python/python-scrapy-debugging-spiders.html"}],["meta",{"property":"og:site_name","content":"Java学习笔记"}],["meta",{"property":"og:title","content":"Scrapy入门（三）-调试(Debugging)Spiders"}],["meta",{"property":"og:description","content":"1. 背景 而Scrapy的爬虫通常是在命令行中启动的，我们怎么去调试呢？ 2. 调试部署 1. 首先在setting.py同级目录下创建run.py文件。 image-20210311105958418 写入以下代码 其中name参数为spider的name。 接着在spider文件中设置断点。 image-20210311110405697 返回r..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:updated_time","content":"2023-02-20T13:42:31.000Z"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"article:modified_time","content":"2023-02-20T13:42:31.000Z"}]]},"headers":[{"level":2,"title":"1. 背景","slug":"_1-背景","link":"#_1-背景","children":[]},{"level":2,"title":"2. 调试部署","slug":"_2-调试部署","link":"#_2-调试部署","children":[]},{"level":2,"title":"参考文章","slug":"参考文章","link":"#参考文章","children":[]}],"git":{"createdTime":1676900551000,"updatedTime":1676900551000,"contributors":[{"name":"zszdevelop","email":"zszdevelop@163.com","commits":1}]},"readingTime":{"minutes":0.69,"words":208},"filePathRelative":"language/python/python-scrapy-debugging-spiders.md","localizedDate":"2023年2月20日","autoDesc":true}');export{e as data};
