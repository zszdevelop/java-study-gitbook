{"code":"(window.webpackJsonp=window.webpackJsonp||[]).push([[36],{1269:function(t,s,a){\"use strict\";a.r(s);var n=a(42),e=Object(n.a)({},(function(){var t=this,s=t.$createElement,n=t._self._c||s;return n(\"ContentSlotsDistributor\",{attrs:{\"slot-key\":t.$parent.slotKey}},[n(\"h1\",{attrs:{id:\"java导出生成word之xml方式\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#java导出生成word之xml方式\"}},[t._v(\"#\")]),t._v(\" java导出生成word之XML方式\")]),t._v(\" \"),n(\"h2\",{attrs:{id:\"_1-简介\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#_1-简介\"}},[t._v(\"#\")]),t._v(\" 1. 简介\")]),t._v(\" \"),n(\"p\",[t._v(\"Word从2003开始支持XML格式，操作流程\")]),t._v(\" \"),n(\"ul\",[n(\"li\",[t._v(\"先用office2003或者2007编辑好word的样式，然后另存为xml，\")]),t._v(\" \"),n(\"li\",[t._v(\"将xml翻译为FreeMarker模板，\")]),t._v(\" \"),n(\"li\",[t._v(\"最后用java来解析FreeMarker模板并输出Doc。\")])]),t._v(\" \"),n(\"p\",[t._v(\"经测试这样方式生成的word文档完全符合office标准，样式、内容控制非常便利，打印也不会变形，生成的文档和office中编辑文档完全一样。\")]),t._v(\" \"),n(\"h2\",{attrs:{id:\"_2-集成使用\"}},[n(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#_2-集成使用\"}},[t._v(\"#\")]),t._v(\" 2. 集成使用\")]),t._v(\" \"),n(\"ol\",[n(\"li\",[n(\"p\",[t._v(\"新建项目\")])]),t._v(\" \"),n(\"li\",[n(\"p\",[t._v(\"引入相关pom依赖 \"),n(\"code\",[t._v(\"FreeMarker\")])]),t._v(\" \"),n(\"div\",{staticClass:\"language- extra-class\"},[n(\"pre\",{pre:!0,attrs:{class:\"language-text\"}},[n(\"code\",[t._v(\"<dependency>\\n    <groupId>org.springframework.boot</groupId>\\n    <artifactId>spring-boot-starter-freemarker</artifactId>\\n</dependency>\\n\")])])])]),t._v(\" \"),n(\"li\",[n(\"p\",[t._v(\"在application.propertes中添加相应配置\")]),t._v(\" \"),n(\"div\",{staticClass:\"language- extra-class\"},[n(\"pre\",{pre:!0,attrs:{class:\"language-text\"}},[n(\"code\",[t._v(\"## Freemarker 配置\\n##模版存放路径（默认为 classpath:/templates/）\\nspring.freemarker.template-loader-path=classpath:/templates/\\n##是否生成缓存，生成环境建议开启（默认为true）\\nspring.freemarker.cache=false\\n##编码\\nspring.freemarker.charset=UTF-8\\nspring.freemarker.check-template-location=true\\n##content-type类型(默认为test/html)\\nspring.freemarker.content-type=text/html\\n## 设定所有request的属性在merge到模板的时候，是否要都添加到model中（默认为false）\\nspring.freemarker.expose-request-attributes=false\\n##设定所有HttpSession的属性在merge到模板的时候，是否要都添加到model中.(默认为false)\\nspring.freemarker.expose-session-attributes=false\\n##RequestContext属性的名称（默认为-）\\nspring.freemarker.request-context-attribute=request\\n##模板后缀(默认为.ftl)\\nspring.freemarker.suffix=.html\\n\")])])])]),t._v(\" \"),n(\"li\",[n(\"p\",[t._v(\"简单准备一份word文档\")]),t._v(\" \"),n(\"p\",[n(\"img\",{attrs:{src:a(670),alt:\"image-20200411212120583\"}})])]),t._v(\" \"),n(\"li\",[n(\"p\",[t._v(\"将word保存为xml格式\")]),t._v(\" \"),n(\"p\",[n(\"img\",{attrs:{src:a(671),alt:\"image-20200411212343004\"}})])]),t._v(\" \"),n(\"li\",[n(\"p\",[t._v(\"打开xml将你要的文字用\"),n(\"code\",[t._v(\"${title}\")]),t._v(\" 来替代。并保存为freemarker模板.ftl文件\")]),t._v(\" \"),n(\"p\",[n(\"img\",{attrs:{src:a(672),alt:\"image-20200411213509998\"}})])]),t._v(\" \"),n(\"li\",[n(\"p\",[t._v(\"将.ftl 文件放在templates目录下\")]),t._v(\" \"),n(\"p\",[n(\"img\",{attrs:{src:a(673),alt:\"image-20200411213744258\"}})])]),t._v(\" \"),n(\"li\",[n(\"p\",[t._v(\"使用freemarker模板设置对应属性值\")]),t._v(\" \"),n(\"div\",{staticClass:\"language-java extra-class\"},[n(\"pre\",{pre:!0,attrs:{class:\"language-java\"}},[n(\"code\",[n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"public\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"class\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"WordTest\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n\\n    \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"private\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Configuration\")]),t._v(\" configuration \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"null\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\\n    \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"public\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"WordTest\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n        configuration \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"new\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Configuration\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        configuration\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"setDefaultEncoding\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"UTF-8\"')]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n    \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n\\n    \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"public\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"static\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"void\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"main\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"String\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),t._v(\" args\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"WordTest\")]),t._v(\" test \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"new\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"WordTest\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        test\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"createWord\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n    \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n\\n    \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"public\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"void\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"createWord\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Map\")]),n(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"<\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"String\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Object\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\">\")])]),t._v(\" dataMap\"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"new\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"HashMap\")]),n(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"<\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"String\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Object\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\">\")])]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"getData\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"dataMap\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"try\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n            configuration\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"setDirectoryForTemplateLoading\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"new\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"File\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"/Users/zsz/Project/demo/2020year/4yue/operationword/src/main/resources/templates\"')]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"catch\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"IOException\")]),t._v(\" e\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n            e\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"printStackTrace\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Template\")]),t._v(\" t\"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"null\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"try\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n            t \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" configuration\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"getTemplate\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"java-operation-word.ftl\"')]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"//获取模板文件\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"catch\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"IOException\")]),t._v(\" e\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n            e\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"printStackTrace\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"File\")]),t._v(\" outFile \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"new\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"File\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"/Users/zsz/Project/demo/2020year/4yue/operationword/toword+\"')]),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"+\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"System\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"currentTimeMillis\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"+\")]),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\".doc\"')]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"//导出文件\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Writer\")]),t._v(\" out \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"null\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"try\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n            out \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"new\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"BufferedWriter\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"new\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"OutputStreamWriter\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"new\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"FileOutputStream\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"outFile\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"catch\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"FileNotFoundException\")]),t._v(\" e1\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n            e1\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"printStackTrace\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"try\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n            t\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"process\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"dataMap\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" out\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"//将填充数据填入模板文件并输出到目标文件\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"catch\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"TemplateException\")]),t._v(\" e\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n            e\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"printStackTrace\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"catch\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"IOException\")]),t._v(\" e\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n            e\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"printStackTrace\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n    \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n\\n    \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"private\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"void\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"getData\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Map\")]),n(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"<\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"String\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Object\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\">\")])]),t._v(\" dataMap\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n        dataMap\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"put\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"title\"')]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"标题设计\"')]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        dataMap\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"put\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"nian\"')]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"2016\"')]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        dataMap\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"put\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"yue\"')]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"3\"')]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        dataMap\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"put\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"ri\"')]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"6\"')]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        dataMap\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"put\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"shenheren\"')]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"lc\"')]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        dataMap\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"put\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"xwdd\"')]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"这是询问地点HHHHHHHHHHHH\"')]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"List\")]),n(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"<\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Map\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"<\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"String\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Object\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\">\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\">\")])]),t._v(\" list \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"new\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"ArrayList\")]),n(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"<\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Map\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"<\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"String\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Object\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\">\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\">\")])]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"for\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"int\")]),t._v(\" i \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"0\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\" i \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"<\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token number\"}},[t._v(\"10\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\" i\"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"++\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n            \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Map\")]),n(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"<\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"String\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Object\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\">\")])]),t._v(\" map \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"new\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"HashMap\")]),n(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"<\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"String\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Object\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\">\")])]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n            map\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"put\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"xuehao\"')]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" i\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n            map\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"put\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"neirong\"')]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"内容\"')]),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"+\")]),t._v(\"i\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n            list\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"add\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"map\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n\\n\\n        dataMap\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"put\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"list\"')]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" list\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n    \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n\\n\"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"//    @Test\")]),t._v(\"\\n    \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"public\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"void\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"genFile\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"throws\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Exception\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// 第一步：创建一个Configuration对象，直接new一个对象。构造方法的参数就是freemarker对于的版本号。\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Configuration\")]),t._v(\" configuration \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"new\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Configuration\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Configuration\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"getVersion\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// 第二步：设置模板文件所在的路径。\")]),t._v(\"\\n        configuration\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"setDirectoryForTemplateLoading\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"new\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"File\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"D:/workspace/e3/e3-item-web/src/main/webapp/WEB-INF/ftl\"')]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// 第三步：设置模板文件使用的字符集。一般就是utf-8.\")]),t._v(\"\\n        configuration\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"setDefaultEncoding\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"utf-8\"')]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// 第四步：加载一个模板，创建一个模板对象。\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Template\")]),t._v(\" template \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" configuration\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"getTemplate\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"hello.ftl\"')]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// 第五步：创建一个模板使用的数据集，可以是pojo也可以是map。一般是Map。\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Map\")]),t._v(\" dataModel \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"new\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"HashMap\")]),n(\"span\",{pre:!0,attrs:{class:\"token generics\"}},[n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"<\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\">\")])]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"//向数据集中添加数据\")]),t._v(\"\\n        dataModel\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"put\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"hello\"')]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"this is my first freemarker test.\"')]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// 第六步：创建一个Writer对象，一般创建一FileWriter对象，指定生成的文件名。\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"Writer\")]),t._v(\" out \"),n(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"new\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"FileWriter\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[t._v(\"new\")]),t._v(\" \"),n(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[t._v(\"File\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token string\"}},[t._v('\"D:/aaa/out/hello.html\"')]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// 第七步：调用模板对象的process方法输出文件。\")]),t._v(\"\\n        template\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"process\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"dataModel\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" out\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n        \"),n(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[t._v(\"// 第八步：关闭流。\")]),t._v(\"\\n        out\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\".\")]),n(\"span\",{pre:!0,attrs:{class:\"token function\"}},[t._v(\"close\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\")\")]),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n    \"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n\"),n(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n\")])])])]),t._v(\" \"),n(\"li\",[n(\"p\",[t._v(\"查看word\")]),t._v(\" \"),n(\"p\",[n(\"img\",{attrs:{src:a(674),alt:\"image-20200411214311413\"}})])])])])}),[],!1,null,null,null);s.default=e.exports},670:function(t,s,a){t.exports=a.p+\"assets/img/image-20200411212120583.707e7fb3.png\"},671:function(t,s,a){t.exports=a.p+\"assets/img/image-20200411212343004.456056cc.png\"},672:function(t,s,a){t.exports=a.p+\"assets/img/image-20200411213509998.2cd9ac43.png\"},673:function(t,s,a){t.exports=a.p+\"assets/img/image-20200411213744258.c708afca.png\"},674:function(t,s,a){t.exports=a.p+\"assets/img/image-20200411214311413.74876d0c.png\"}}]);","extractedComments":[]}